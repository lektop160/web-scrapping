# Пример парсинга данных с использованием Python, BeautifulSoup и SQLite

Этот проект демонстрирует пример парсинга веб-страниц с использованием библиотек Python, сохранение данных в базу данных SQLite и просмотр результатов.

### Используемые инструменты и библиотеки:

- **Python 3**: Язык программирования для разработки скриптов и приложений.
- **BeautifulSoup**: Библиотека Python для парсинга HTML и XML документов.
- **SQLite**: Легковесная база данных, используемая для хранения и управления данными.
- **Requests**: Библиотека Python для выполнения HTTP-запросов.
- **Fake User-Agent**: Библиотека для генерации случайного User-Agent для HTTP-запросов.
- **time**: Модуль Python для работы с временем и задержками.

### Как использовать:

1. **Установка зависимостей**:
   Убедитесь, что у вас установлены необходимые библиотеки, выполнив:
   ```
   pip install requests beautifulsoup4 fake-useragent
   ```

2. **Запуск скрипта**:
   - Скрипт `web_scraping.py` начинает с парсинга указанного URL (`https://guide.kaspi.kz/client/ru`) с помощью функции `findMainUrl`.
   - Для каждой найденной ссылки на странице осуществляется парсинг содержимого с использованием функций `Scrapping` и `getElements`.
   - Результаты парсинга (заголовок, дата и содержимое) сохраняются в базу данных SQLite (`scraped_data.db`).

3. **Просмотр данных**:
   - Для просмотра данных из базы данных вы можете использовать **DB Browser for SQLite** или **Visual Studio Code с расширением SQLite**.
   - Откройте файл `scraped_data.db` в выбранной программе и выполните SQL-запросы для просмотра и анализа данных.

### Структура проекта:

- `web_scraping.py`: Основной скрипт для парсинга данных и сохранения в базу данных.
- `scraped_data.db`: Файл базы данных SQLite для хранения данных.
- `README.md`: Этот файл, содержащий краткое описание проекта и инструкции.

### Замечания:

- Предоставленный код демонстрирует базовый пример парсинга и сохранения данных. Для реального использования его следует адаптировать под конкретные требования и условия вашего проекта.
- Убедитесь, что ваши HTTP-запросы к сайтам соответствуют их политике использования и не нарушают правила.
